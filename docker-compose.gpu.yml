version: '3.8'

services:
  # PostgreSQL with pgvector
  postgres:
    image: pgvector/pgvector:pg15
    container_name: auto-match-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-auto_match}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/scripts/init_pgvector.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis (for caching - optional for now)
  redis:
    image: redis:7-alpine
    container_name: auto-match-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Embedding Service (GPU 지원)
  embedding:
    build:
      context: ./embedding-service
      dockerfile: Dockerfile.gpu  # GPU용 Dockerfile
    container_name: auto-match-embedding-gpu
    ports:
      - "8001:8001"
    environment:
      - MODEL_NAME=jhgan/ko-sroberta-multitask
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ml_models:/root/.cache/torch
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Backend API (GPU 지원)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.gpu  # GPU용 Dockerfile
    container_name: auto-match-backend-gpu
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-auto_match}
      - REDIS_URL=redis://redis:6379/0
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - DEBUG=${DEBUG:-true}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-dev-secret-key-change-in-production}
      - JWT_ALGORITHM=${JWT_ALGORITHM:-HS256}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-jhgan/ko-sroberta-multitask}
      - EMBEDDING_DIMENSION=${EMBEDDING_DIMENSION:-768}
      - ML_MODELS_PATH=/app/ml_models
      - UPLOAD_DIR=/app/uploads
      - EMBEDDING_SERVICE_URL=http://embedding:8001
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./backend:/app
      - ./data:/data
      - ml_models:/app/ml_models
      - upload_files:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
        reservations:
          memory: 4G

volumes:
  postgres_data:
  redis_data:
  ml_models:
  upload_files:
